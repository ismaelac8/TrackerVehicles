{"cells":[{"cell_type":"markdown","metadata":{"id":"acoustic-digit"},"source":["*Autor Ismael Aguilera* - Trabajo de fin de grado - Detección de vehículos en videos de tráfico\n","\n"],"id":"acoustic-digit"},{"cell_type":"markdown","metadata":{"id":"-Sfz0aMs71_u"},"source":["## Instalar dependencias"],"id":"-Sfz0aMs71_u"},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xlDQRO7q8awr","outputId":"f8fa0932-6102-4cfa-93c2-6c0a70df0001","executionInfo":{"status":"ok","timestamp":1664810167378,"user_tz":-120,"elapsed":8110,"user":{"displayName":"Ismael Aguilera","userId":"11848629486211321319"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: ffmpeg in /usr/local/lib/python3.7/dist-packages (1.4)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# %%bash\n","!pip install -qr https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt  # install dependencies\n","!pip install ffmpeg\n","from google.colab import drive\n","drive.mount('/content/drive')"],"id":"xlDQRO7q8awr"},{"cell_type":"markdown","metadata":{"id":"Cyo88gAz8ypD"},"source":["## Generar información (subprograma)\n"],"id":"Cyo88gAz8ypD"},{"cell_type":"code","execution_count":15,"metadata":{"id":"nRh84zV-xqjf","executionInfo":{"status":"ok","timestamp":1664810167380,"user_tz":-120,"elapsed":21,"user":{"displayName":"Ismael Aguilera","userId":"11848629486211321319"}}},"outputs":[],"source":["#!pip install Pillow==9.0.0\n","import torch\n","import torchvision\n","import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","import torchvision.transforms.functional as F\n","import torchvision.transforms as T\n","import cv2\n","import pandas as pd\n","\n","#import PIL\n","#!pip install -U pillow\n","#!pip install pytesseract\n","\n","def generarInformacion(rutaImg, rutaInfo):\n","  \n","  # Model\n","  model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n","\n","  # Inference\n","  results = model(rutaImg)\n","\n","  # Results\n","  results.print()\n","  results.save(rutaInfo)  # or .show()\n","\n","  results.xyxy[0]  # img1 predictions (tensor)\n","  results.pandas().xyxy[0]  # img1 predictions (pandas)\n","  file1 = open(rutaInfo, \"w\")\n","  rutaInfoCsv = rutaInfo + \".csv\"\n","  file1.write(str(results.pandas().xyxy[0]))\n","  file1.close()\n","  results.pandas().xyxy[0].to_csv(rutaInfoCsv)"],"id":"nRh84zV-xqjf"},{"cell_type":"markdown","metadata":{"id":"Vb2ah7-O83YM"},"source":["## Pintar información (subprograma)"],"id":"Vb2ah7-O83YM"},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":6269,"status":"ok","timestamp":1664810173631,"user":{"displayName":"Ismael Aguilera","userId":"11848629486211321319"},"user_tz":-120},"id":"rP0wlMhH3Y33","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e227b2fa-4e8e-4948-b66c-35b93f2d9980"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: norfair[video] in /usr/local/lib/python3.7/dist-packages (2.0.0)\n","Requirement already satisfied: rich<13.0.0,>=9.10.0 in /usr/local/lib/python3.7/dist-packages (from norfair[video]) (12.6.0)\n","Requirement already satisfied: filterpy<2.0.0,>=1.4.5 in /usr/local/lib/python3.7/dist-packages (from norfair[video]) (1.4.5)\n","Requirement already satisfied: opencv-python<5.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from norfair[video]) (4.6.0.66)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from filterpy<2.0.0,>=1.4.5->norfair[video]) (3.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from filterpy<2.0.0,>=1.4.5->norfair[video]) (1.7.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from filterpy<2.0.0,>=1.4.5->norfair[video]) (1.21.6)\n","Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from rich<13.0.0,>=9.10.0->norfair[video]) (0.9.1)\n","Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich<13.0.0,>=9.10.0->norfair[video]) (2.6.1)\n","Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from rich<13.0.0,>=9.10.0->norfair[video]) (4.1.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy<2.0.0,>=1.4.5->norfair[video]) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy<2.0.0,>=1.4.5->norfair[video]) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy<2.0.0,>=1.4.5->norfair[video]) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy<2.0.0,>=1.4.5->norfair[video]) (1.4.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->filterpy<2.0.0,>=1.4.5->norfair[video]) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: yolov5 in /usr/local/lib/python3.7/dist-packages (6.2.1)\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from yolov5) (3.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from yolov5) (0.11.2)\n","Requirement already satisfied: fire in /usr/local/lib/python3.7/dist-packages (from yolov5) (0.4.0)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from yolov5) (6.0)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from yolov5) (2.8.0)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from yolov5) (1.12.1+cu113)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from yolov5) (7.9.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from yolov5) (1.7.3)\n","Requirement already satisfied: boto3>=1.19.1 in /usr/local/lib/python3.7/dist-packages (from yolov5) (1.24.84)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.7/dist-packages (from yolov5) (4.64.1)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from yolov5) (1.3.5)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from yolov5) (9.2.0)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from yolov5) (0.13.1+cu113)\n","Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from yolov5) (0.1.1.post2209072238)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from yolov5) (2.23.0)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from yolov5) (4.6.0.66)\n","Requirement already satisfied: sahi>=0.10.5 in /usr/local/lib/python3.7/dist-packages (from yolov5) (0.10.7)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from yolov5) (1.21.6)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from yolov5) (5.4.8)\n","Requirement already satisfied: botocore<1.28.0,>=1.27.84 in /usr/local/lib/python3.7/dist-packages (from boto3>=1.19.1->yolov5) (1.27.84)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3>=1.19.1->yolov5) (1.0.1)\n","Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3>=1.19.1->yolov5) (0.6.0)\n","Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.84->boto3>=1.19.1->yolov5) (1.25.11)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.84->boto3>=1.19.1->yolov5) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->yolov5) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->yolov5) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->yolov5) (0.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.2.2->yolov5) (4.1.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->yolov5) (2022.2.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.84->boto3>=1.19.1->yolov5) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->yolov5) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->yolov5) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->yolov5) (3.0.4)\n","Requirement already satisfied: terminaltables in /usr/local/lib/python3.7/dist-packages (from sahi>=0.10.5->yolov5) (3.1.10)\n","Requirement already satisfied: click==8.0.4 in /usr/local/lib/python3.7/dist-packages (from sahi>=0.10.5->yolov5) (8.0.4)\n","Requirement already satisfied: shapely>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from sahi>=0.10.5->yolov5) (1.8.4)\n","Requirement already satisfied: pybboxes==0.1.5 in /usr/local/lib/python3.7/dist-packages (from sahi>=0.10.5->yolov5) (0.1.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click==8.0.4->sahi>=0.10.5->yolov5) (4.12.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->yolov5) (0.6.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->yolov5) (57.4.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->yolov5) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->yolov5) (1.0.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->yolov5) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->yolov5) (3.4.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->yolov5) (0.4.6)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->yolov5) (3.17.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->yolov5) (1.35.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->yolov5) (0.37.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->yolov5) (1.48.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->yolov5) (4.9)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->yolov5) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->yolov5) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->yolov5) (1.3.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click==8.0.4->sahi>=0.10.5->yolov5) (3.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->yolov5) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->yolov5) (3.2.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire->yolov5) (1.1.0)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->yolov5) (2.0.10)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->yolov5) (2.6.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->yolov5) (4.4.2)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->yolov5) (0.2.0)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->yolov5) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->yolov5) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->yolov5) (5.1.1)\n","Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from ipython->yolov5) (0.18.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->yolov5) (0.8.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->yolov5) (0.2.5)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->yolov5) (0.7.0)\n"]}],"source":["from IPython.core.display import Image\n","\n","import cv2\n","import numpy as np\n","import csv\n","from csv import reader\n","import math\n","import pandas as pd\n","import cv2 as cv\n","#from tracker import *\n","!pip install norfair[video]\n","!pip install yolov5\n","import norfair\n","from norfair import Detection, Tracker, Video, Paths\n","\n","import io\n","from base64 import b64encode\n","from IPython.display import HTML\n","\n","conta = 0;\n","\n","detections = []\n","\n","def pintarInformacion2(rutaImg, rutaInfo, rutaPintada):\n","\n","  # Creamos el object tracker\n","  #tracker = EuclideanDistTracker()\n","\n","  #cap = cv2.VideoCapture(filename)\n","\n","  # Creamos el object detector\n","  #object_detector = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=40)\n","      \n","  #Coger valores de csv\n","  with open(rutaInfo, newline='') as f:\n","    reader = csv.reader(f,delimiter=',')\n","    line = list(reader)\n","\n","  with open(rutaInfo, \"r\") as fp:\n","    numlin = len(fp.readlines()) \n","\n","  frame = cv2.imread(rutaImg)\n","\n","\n","  # Hacemos la detección de objetos\n","  i = 1\n","  while i<numlin:\n","    x = int(float(line[i][1]))\n","    y = int(float(line[i][2]))\n","    w = int(float(line[i][3]))\n","    h = int(float(line[i][4]))\n","    con = int(float(line[i][5]))\n","    cx = int((x+w)/2)\n","    cy = int((y+h)/2)\n","    i = i + 1;\n","    cv2.rectangle(frame, (x,y), (w,h), (0,255,0), 2)    \n","      \n","    #detections.append([x, y, w, h])\n","\n","  # Realizamos el object tracking\n","  #boxes_ids = tracker.update(detections)\n","  #for box_id in boxes_ids:\n","  #    x, y, w, h, id = box_id\n","  #    cv2.putText(frame, str(id), (x, y - 15), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2)\n","      #cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n","\n","  cv2.imwrite(rutaPintada,frame)\n","\n","  #cap.release()\n","  cv2.destroyAllWindows()"],"id":"rP0wlMhH3Y33"},{"cell_type":"markdown","metadata":{"id":"WHl9XuE80QCC"},"source":["\n","## Pintar tracking (subprograma)"],"id":"WHl9XuE80QCC"},{"cell_type":"code","execution_count":17,"metadata":{"id":"eW0_z21vX3gr","executionInfo":{"status":"ok","timestamp":1664810173633,"user_tz":-120,"elapsed":19,"user":{"displayName":"Ismael Aguilera","userId":"11848629486211321319"}}},"outputs":[],"source":["#!wget \"https://raw.githubusercontent.com/tryolabs/norfair/master/demos/yolov5/yolov5demo.py\" -O yolov5demo.py\n","import shutil\n","shutil.copy('/content/drive/MyDrive/videostrafico/yolov5demo.py', \"/content/\")\n","def pintarTracking():\n","  !python yolov5demo.py sample.mp4 --img_size 1280 --conf_thres 0.4 --classes 0 1 2 3 4 5 6 7 8 --track_points 'bbox'"],"id":"eW0_z21vX3gr"},{"cell_type":"markdown","metadata":{"id":"gN7KcsVe9DWx"},"source":["## Dividir en frames el video\n"],"id":"gN7KcsVe9DWx"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":252},"executionInfo":{"elapsed":1090,"status":"error","timestamp":1662510861388,"user":{"displayName":"Ismael Aguilera","userId":"11848629486211321319"},"user_tz":-120},"id":"thUiq_4Vl_Yt","outputId":"cf563663-3f6a-4b46-acec-6d14f4619261"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/videostrafico/df/%02d.png\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-8dc3d4f01c92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mfps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAP_PROP_FPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mamount_of_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import cv2\n","import os\n","import subprocess\n","import shutil\n","\n","filename = \"/content/drive/MyDrive/videostrafico/videocarla1.mp4\"\n","#filename = \"/content/drive/MyDrive/videostrafico/cctv052x2004080519x01687.avi\"\n","\n","saveDirFilenames = \"/content/drive/MyDrive/videostrafico/df/%02d.png\"\n","print(saveDirFilenames)\n","\n","fname = str(filename)\n","cap = cv2.VideoCapture(fname)\n","fps = cap.get(cv2.CAP_PROP_FPS)\n","amount_of_frames = cap.get(7)\n","print('Numero de frames en el video = ',amount_of_frames)\n","print('Extrayendo frames')\n","command = str('ffmpeg -i ' +'\"'+ str(fname)+'\"' + ' ' + '-q:v 1' + ' ' + '-start_number 0' + ' '+'\"'+ str(saveDirFilenames)+'\"')\n","print(command)\n","subprocess.call(command, shell=True)\n","print('Frames extraidos correctamente')\n"],"id":"thUiq_4Vl_Yt"},{"cell_type":"markdown","metadata":{"id":"vnAu-CxU9J8d"},"source":["## Generar información de cada frame"],"id":"vnAu-CxU9J8d"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Q1qAshYgZWvo5LgyiOfndlJ27CyYrLCz"},"executionInfo":{"elapsed":28876,"status":"error","timestamp":1662134445451,"user":{"displayName":"Ismael Aguilera","userId":"11848629486211321319"},"user_tz":-120},"id":"bXjxhOTk1EiX","outputId":"14fe49e2-9bf0-482e-df1b-d2eb2968720c"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["amount_of_frames = 6051\n","rutaImgIni = \"/content/drive/MyDrive/videostrafico/df/\"\n","saveRutaInfoIni = \"/content/drive/MyDrive/videostrafico/rutaInformacion/results\"\n","cont = 0\n","while cont<amount_of_frames:\n","  if (cont < 10):\n","      rutaImg = rutaImgIni + \"0\" + str(cont) + \".png\"\n","      #rutaImg = rutaImgIni + \"in00000\" + str(cont) + \".jpg\"\n","  else:\n","      rutaImg = rutaImgIni + str(cont) + \".png\"\n","  saveRutaInfo = saveRutaInfoIni + str(cont) + \".txt\"\n","  print(rutaImg)\n","  print(saveRutaInfo)\n","  generarInformacion(rutaImg,saveRutaInfo)\n","  cont = cont + 1\n","cont = 0"],"id":"bXjxhOTk1EiX"},{"cell_type":"markdown","metadata":{"id":"KX_K4j3a9hWw"},"source":["## Pintar información de cada frame"],"id":"KX_K4j3a9hWw"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"o8CvIjbF3JwU"},"outputs":[],"source":["rutaImgIni = \"/content/drive/MyDrive/videostrafico/df/\"\n","RutaInfoIni = \"/content/drive/MyDrive/videostrafico/rutaInformacion/results\"\n","rutaImgPinIni = '/content/drive/MyDrive/videostrafico/imagenesPintadas/'\n","cont = 0\n","while cont<amount_of_frames:\n","  if (cont < 10):\n","      rutaImg = rutaImgIni + \"0\" + str(cont) + \".png\"\n","      #rutaImg = rutaImgIni + \"in00000\" + str(cont) + \".jpg\"\n","  else:\n","      rutaImg = rutaImgIni + str(cont) + \".png\"\n","  RutaInfo = RutaInfoIni + str(cont) + \".txt.csv\"\n","  rutaImgPin = rutaImgPinIni + str(cont) + \"ip.png\"\n","  print(rutaImg)\n","  print(RutaInfo)\n","  print(rutaImgPin)\n","  #pintarInformacion(rutaImg,RutaInfo, rutaImgPin)\n","  pintarInformacion2(rutaImg,RutaInfo, rutaImgPin)    \n","  cont = cont + 1\n","cont = 0"],"id":"o8CvIjbF3JwU"},{"cell_type":"markdown","metadata":{"id":"xDKE5cKy7eHM"},"source":["## Generar video en base a frames"],"id":"xDKE5cKy7eHM"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"elapsed":8,"status":"error","timestamp":1661167752964,"user":{"displayName":"Ismael Aguilera","userId":"11848629486211321319"},"user_tz":-120},"id":"BNqQ2C-p7duo","outputId":"2823039c-fe6c-4386-903d-8d7e508c844f"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-8eed4c283007>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrutaImg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrutaImgPinIni\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0mcont\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mamount_of_frames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcont\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mrutaImg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrutaImgIni\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"0\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcont\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'amount_of_frames' is not defined"]}],"source":["rutaImgPinIni = \"/content/drive/MyDrive/videostrafico/df/\"\n","cont = 1\n","img_array = []\n","rutaImg = rutaImgPinIni\n","while cont<amount_of_frames:\n","  if (cont < 10):\n","    rutaImg = rutaImgIni + \"0\" + str(cont) + \".png\"\n","    #rutaImg = rutaImgIni + \"in00000\" + str(cont) + \".jpg\"\n","  else:\n","      rutaImg = rutaImgIni + str(cont) + \".png\"\n","  print(rutaImg)\n","  img = cv2.imread(rutaImg)\n","  height, width, layers = img.shape\n","  size = (width,height)\n","  img_array.append(img)\n","\n","  cont = cont + 1\n","\n","fourcc = cv2.VideoWriter_fourcc(*'mpeg')\n","out = cv2.VideoWriter()\n","out.open('/content/drive/MyDrive/videostrafico/videopintado/videoFrames.mp4',fourcc,10,size,True)\n","\n","for i in range(len(img_array)):\n","  out.write(img_array[i])\n","out.release()\n","\n","cont = 0"],"id":"BNqQ2C-p7duo"},{"cell_type":"markdown","metadata":{"id":"iXyOQ1Zd7Zo5"},"source":["## Generar video con bounding boxes"],"id":"iXyOQ1Zd7Zo5"},{"cell_type":"code","execution_count":null,"metadata":{"id":"zqM8wreC7dsU"},"outputs":[],"source":["rutaImgPinIni = \"/content/drive/MyDrive/videostrafico/imagenesPintadas/\"\n","cont = 0\n","img_array = []\n","while cont<amount_of_frames:\n","  rutaImgPin = rutaImgPinIni + str(cont) + \"ip.png\"\n","  print(rutaImgPin)\n","  img = cv2.imread(rutaImgPin)\n","  height, width, layers = img.shape\n","  size = (width,height)\n","  img_array.append(img)\n","\n","  cont = cont + 1\n","\n","fourcc = cv2.VideoWriter_fourcc(*'mpeg')\n","out = cv2.VideoWriter()\n","out.open('/content/drive/MyDrive/videostrafico/videopintado/v1.mp4',fourcc,10,size,True)\n","\n","for i in range(len(img_array)):\n","  out.write(img_array[i])\n","out.release()\n","\n","cont = 0"],"id":"zqM8wreC7dsU"},{"cell_type":"markdown","metadata":{"id":"bzbUVSnK0ewf"},"source":["## Pintar tracking"],"id":"bzbUVSnK0ewf"},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":31284,"status":"ok","timestamp":1664810204901,"user":{"displayName":"Ismael Aguilera","userId":"11848629486211321319"},"user_tz":-120},"id":"Inv4wchs0Csg","outputId":"3ea7632e-c7f0-4a8f-dd2c-60b542a3337b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n","YOLOv5 🚀 2022-10-3 Python-3.7.14 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n","Adding AutoShape... \n","\u001b[2K ...  \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m11.08fps\u001b[0m\n","\u001b[?25h\u001b[37mOutput video file saved to: .\u001b[0m\u001b[37m/\u001b[0m\u001b[37msample_out.mp4\u001b[0m\n","El máximo id es:  56\n","Coefficients: \n"," [   -0.41144]\n","Coefficients: \n"," [   0.026138]\n","Coefficients: \n"," [    0.77895]\n","Coefficients: \n"," [   0.054435]\n","Coefficients: \n"," [   -0.67802]\n","Coefficients: \n"," [     7.2447]\n","Coefficients: \n"," [   -0.72678]\n","Coefficients: \n"," [    0.86682]\n","Coefficients: \n"," [   -0.36186]\n","Coefficients: \n"," [  -0.099198]\n","Coefficients: \n"," [   -0.19959]\n","Coefficients: \n"," [   -0.82922]\n","Coefficients: \n"," [    -0.8775]\n","Coefficients: \n"," [     1.2138]\n","Coefficients: \n"," [   -0.65035]\n","Coefficients: \n"," [   -0.25868]\n","Coefficients: \n"," [  -0.027128]\n","Coefficients: \n"," [  -0.045827]\n","Coefficients: \n"," [    -1.7441]\n","Coefficients: \n"," [    -3.8728]\n","Coefficients: \n"," [    -1.7229]\n","Coefficients: \n"," [    -1.9819]\n","Coefficients: \n"," [    -2.8793]\n","Coefficients: \n"," [     1.1353]\n","Coefficients: \n"," [    -2.9031]\n","Coefficients: \n"," [    -2.6559]\n","Coefficients: \n"," [    -2.5522]\n","Coefficients: \n"," [    -2.6795]\n","Coefficients: \n"," [    -3.0339]\n","Coefficients: \n"," [    -2.1861]\n","Coefficients: \n"," [    -1.8526]\n","Coefficients: \n"," [      6.744]\n","Coefficients: \n"," [  -0.071196]\n","Coefficients: \n"," [    -12.249]\n","Coefficients: \n"," [    -5.4934]\n","Coefficients: \n"," [    -1.6803]\n","Coefficients: \n"," [    -7.5159]\n","Coefficients: \n"," [    -20.473]\n","Coefficients: \n"," [    -4.3004]\n","Coefficients: \n"," [    -4.1117]\n","Coefficients: \n"," [    -25.735]\n","Coefficients: \n"," [    -4.7531]\n","Coefficients: \n"," [    0.21218]\n","Coefficients: \n"," [     19.292]\n","Coefficients: \n"," [     40.856]\n","Coefficients: \n"," [     7.0188]\n","Coefficients: \n"," [    -2.3155]\n","Coefficients: \n"," [    -1.4616]\n","Coefficients: \n"," [     -1.168]\n","Coefficients: \n"," [    -11.253]\n","Coefficients: \n"," [    -31.851]\n","Coefficients: \n"," [    -29.395]\n","Coefficients: \n"," [     105.13]\n","Coefficients: \n"," [     28.061]\n","Coefficients: \n"," [          0]\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/videostrafico/videopintado/sampleVideoFrames.mp4'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}],"source":["import shutil\n","shutil.copy('/content/drive/MyDrive/videostrafico/videopintado/videocarla1.mp4', \"/content/sample.mp4\")\n","pintarTracking()\n","shutil.copy(\"/content/sample_out.mp4\", \"/content/drive/MyDrive/videostrafico/videopintado/sampleVideoFrames.mp4\")"],"id":"Inv4wchs0Csg"},{"cell_type":"markdown","metadata":{"id":"JKeofe57ONGR"},"source":[],"id":"JKeofe57ONGR"},{"cell_type":"markdown","metadata":{"id":"BVOQzUQt9qFf"},"source":["## Generar video al juntar frames\n"],"id":"BVOQzUQt9qFf"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zlwvpb-M6vy-"},"outputs":[],"source":["rutaImgPinIni = \"/content/drive/MyDrive/videostrafico/imagenesPintadas/\"\n","cont = 0\n","img_array = []\n","while cont<amount_of_frames:\n","  rutaImgPin = rutaImgPinIni + str(cont) + \"ip.png\"\n","  print(rutaImgPin)\n","  img = cv2.imread(rutaImgPin)\n","  height, width, layers = img.shape\n","  size = (width,height)\n","  img_array.append(img)\n","\n","  cont = cont + 1\n","\n","fourcc = cv2.VideoWriter_fourcc(*'mpeg')\n","out = cv2.VideoWriter()\n","out.open('/content/drive/MyDrive/videostrafico/videopintado/v1.mp4',fourcc,10,size,True)\n","\n","for i in range(len(img_array)):\n","  out.write(img_array[i])\n","out.release()\n","\n","cont = 0"],"id":"Zlwvpb-M6vy-"},{"cell_type":"markdown","metadata":{"id":"B9FKzQ6A-X44"},"source":["## Model Description \n","\n","<img width=\"800\" alt=\"YOLOv5 Model Comparison\" src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/model_comparison.png\">\n","&nbsp;\n","\n","[YOLOv5](https://ultralytics.com/yolov5) 🚀 is a family of compound-scaled object detection models trained on the COCO dataset, and includes simple functionality for Test Time Augmentation (TTA), model ensembling, hyperparameter evolution, and export to ONNX, CoreML and TFLite.\n","\n","|Model |size<br><sup>(pixels) |mAP<sup>val<br>0.5:0.95 |mAP<sup>test<br>0.5:0.95 |mAP<sup>val<br>0.5 |Speed<br><sup>V100 (ms) | |params<br><sup>(M) |FLOPS<br><sup>640 (B)\n","|---   |---  |---        |---         |---             |---                |---|---              |---\n","|[YOLOv5s6](https://github.com/ultralytics/yolov5/releases)   |1280 |43.3     |43.3     |61.9     |**4.3** | |12.7  |17.4\n","|[YOLOv5m6](https://github.com/ultralytics/yolov5/releases)   |1280 |50.5     |50.5     |68.7     |8.4     | |35.9  |52.4\n","|[YOLOv5l6](https://github.com/ultralytics/yolov5/releases)   |1280 |53.4     |53.4     |71.1     |12.3    | |77.2  |117.7\n","|[YOLOv5x6](https://github.com/ultralytics/yolov5/releases)   |1280 |**54.4** |**54.4** |**72.0** |22.4    | |141.8 |222.9\n","|[YOLOv5x6](https://github.com/ultralytics/yolov5/releases) TTA |1280 |**55.0** |**55.0** |**72.0** |70.8 | |-  |-\n","\n","<details>\n","  <summary>Table Notes (click to expand)</summary>\n","\n","  * AP<sup>test</sup> denotes COCO [test-dev2017](http://cocodataset.org/#upload) server results, all other AP results denote val2017 accuracy.\n","  * AP values are for single-model single-scale unless otherwise noted. **Reproduce mAP** by `python test.py --data coco.yaml --img 640 --conf 0.001 --iou 0.65`\n","  * Speed<sub>GPU</sub> averaged over 5000 COCO val2017 images using a GCP [n1-standard-16](https://cloud.google.com/compute/docs/machine-types#n1_standard_machine_types) V100 instance, and includes FP16 inference, postprocessing and NMS. **Reproduce speed** by `python test.py --data coco.yaml --img 640 --conf 0.25 --iou 0.45`\n","  * All checkpoints are trained to 300 epochs with default settings and hyperparameters (no autoaugmentation).\n","  * Test Time Augmentation ([TTA](https://github.com/ultralytics/yolov5/issues/303)) includes reflection and scale augmentation. **Reproduce TTA** by `python test.py --data coco.yaml --img 1536 --iou 0.7 --augment`\n","\n","</details>\n","\n","<p align=\"left\"><img width=\"800\" src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/model_plot.png\"></p>\n","\n","<details>\n","  <summary>Figure Notes (click to expand)</summary>\n","\n","  * GPU Speed measures end-to-end time per image averaged over 5000 COCO val2017 images using a V100 GPU with batch size 32, and includes image preprocessing, PyTorch FP16 inference, postprocessing and NMS.\n","  * EfficientDet data from [google/automl](https://github.com/google/automl) at batch size 8.\n","  * **Reproduce** by `python test.py --task study --data coco.yaml --iou 0.7 --weights yolov5s6.pt yolov5m6.pt yolov5l6.pt yolov5x6.pt`\n","\n","</details>\n","\n","## Load From PyTorch Hub\n","\n","\n","This example loads a pretrained **YOLOv5s** model and passes an image for inference. YOLOv5 accepts **URL**, **Filename**, **PIL**, **OpenCV**, **Numpy** and **PyTorch** inputs, and returns detections in **torch**, **pandas**, and **JSON** output formats. See our [YOLOv5 PyTorch Hub Tutorial](https://github.com/ultralytics/yolov5/issues/36) for details."],"id":"B9FKzQ6A-X44"},{"cell_type":"markdown","metadata":{"id":"august-winter"},"source":["## Citation\n","\n","[![DOI](https://zenodo.org/badge/264818686.svg)](https://zenodo.org/badge/latestdoi/264818686)\n","\n","\n","## Contact\n","\n","\n","**Issues should be raised directly in https://github.com/ultralytics/yolov5.** For business inquiries or professional support requests please visit [https://ultralytics.com](https://ultralytics.com) or email Glenn Jocher at [glenn.jocher@ultralytics.com](mailto:glenn.jocher@ultralytics.com).\n","\n","\n","&nbsp;"],"id":"august-winter"}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["-Sfz0aMs71_u","Cyo88gAz8ypD","Vb2ah7-O83YM","gN7KcsVe9DWx","vnAu-CxU9J8d","KX_K4j3a9hWw","xDKE5cKy7eHM","iXyOQ1Zd7Zo5","BVOQzUQt9qFf"],"provenance":[{"file_id":"https://github.com/pytorch/pytorch.github.io/blob/master/assets/hub/ultralytics_yolov5.ipynb","timestamp":1652783392537}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":5}